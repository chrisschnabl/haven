# Get tokens/s
python analysis/token_metrics_analyzer.py --dir /Users/chris/haven/analysis/remote_experiments/host4b

# 
Analyzing 3 files:
- llama_summaries.parquet
- llama_classification.parquet
- llama_toxic.analysis.parquet

Metrics Summary:
--------------------------------------------------
total_duration: 3845.0582
total_token_count: 13618.0000
total_tokenize_duration: 0.4090
total_prompt_duration: 39392.8561
total_prompt_tokens: 213277.0000
tokens_per_second: 3.5417
prompt_tokens_per_second: 5.4141